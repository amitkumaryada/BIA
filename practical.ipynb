{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6374cdf7",
   "metadata": {},
   "source": [
    "# Agent Architectures in Practice — Multi‑Framework Lab (Fixed)\n",
    "This version is organized into clear sections with code that **runs** (with graceful fallbacks).  \n",
    "If you haven't installed the optional libraries yet, the cells will skip those sections and explain what to install."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af3662",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install (uncomment if needed). Run this cell, then restart the kernel.\n",
    "# Note: package names are intentionally explicit to avoid version confusion.\n",
    "# !pip install -U langchain langchain-openai langchain-community crewai pyautogen chromadb\n",
    "\n",
    "import os\n",
    "\n",
    "# Read API keys if available (optional for sections that use OpenAI)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"Tip: Set OPENAI_API_KEY in your environment if you want to use OpenAI-backed sections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c59b0",
   "metadata": {},
   "source": [
    "## 1) CrewAI — Role-based Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from crewai import Agent, Task, Crew, Process\n",
    "    # Optional LLM via LangChain (CrewAI can also use other providers)\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    llm = None\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    else:\n",
    "        print(\"OPENAI_API_KEY not set — CrewAI will run with no LLM (agents will be configured but kickoff may be limited).\")\n",
    "\n",
    "    researcher = Agent(\n",
    "        role=\"Researcher\",\n",
    "        goal=\"Analyze LLMs and extract pros/cons for GPT-4, Claude, and Mistral.\",\n",
    "        backstory=\"You specialize in balanced evaluations of foundation models.\",\n",
    "        verbose=True,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    writer = Agent(\n",
    "        role=\"Writer\",\n",
    "        goal=\"Summarize findings into a concise comparison table and bullet list.\",\n",
    "        backstory=\"You convert technical findings into clear outputs for executives.\",\n",
    "        verbose=True,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    task_research = Task(\n",
    "        description=\"Research the strengths, weaknesses, and ideal use-cases of GPT-4, Claude, and Mistral. Return ~6 bullets per model.\",\n",
    "        agent=researcher,\n",
    "        expected_output=\"A structured bullet list per model with at least one risk/limitation called out.\"\n",
    "    )\n",
    "\n",
    "    task_write = Task(\n",
    "        description=\"Turn the research into a one-paragraph summary + a compact table with at least 4 comparison dimensions.\",\n",
    "        agent=writer,\n",
    "        expected_output=\"One paragraph + a Markdown table. Keep it neutral and cite sources if any were used.\"\n",
    "    )\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=[researcher, writer],\n",
    "        tasks=[task_research, task_write],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    print(\"CrewAI: constructed crew with 2 agents and 2 tasks.\")\n",
    "    # Running kickoff requires an LLM; if no key is set, we skip actual execution.\n",
    "    if llm:\n",
    "        result = crew.kickoff()\n",
    "        print(\"\\n=== CrewAI result (truncated) ===\\n\")\n",
    "        print(str(result)[:1200])\n",
    "    else:\n",
    "        print(\"Skipped kickoff because OPENAI_API_KEY was not provided.\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"CrewAI section skipped. Missing package:\", e.name)\n",
    "    print(\"Install with: pip install crewai langchain-openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a6a5f",
   "metadata": {},
   "source": [
    "## 2) LangChain — Tool‑Using Agent (Zero‑Shot ReAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from langchain.agents import initialize_agent, AgentType, Tool\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    # A simple stub tool; replace with a real search tool if desired.\n",
    "    def web_search(query: str) -> str:\n",
    "        return f\"[stub] Search result for: {query}\"\n",
    "\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"web_search\",\n",
    "            func=web_search,\n",
    "            description=\"Use this to look up facts before answering.\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    llm = None\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    else:\n",
    "        print(\"OPENAI_API_KEY not set — using a tool-only skeleton; agent call will be skipped.\")\n",
    "\n",
    "    if llm:\n",
    "        agent = initialize_agent(\n",
    "            tools=tools,\n",
    "            llm=llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "        )\n",
    "        response = agent.run(\"Compare GPT-4, Claude, and Mistral in 5 bullets each.\")\n",
    "        print(response)\n",
    "    else:\n",
    "        # Even without LLM, we can show the tool works\n",
    "        print(web_search(\"LLM comparison dimensions\"))\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"LangChain section skipped. Missing package:\", e.name)\n",
    "    print(\"Install with: pip install langchain langchain-openai langchain-community\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90514f6a",
   "metadata": {},
   "source": [
    "## 3) AutoGen — Two‑Agent Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"OPENAI_API_KEY not set — AutoGen demo will define agents but skip the conversation.\")\n",
    "        config_list = []\n",
    "    else:\n",
    "        # Minimal config_list for OpenAI-compatible providers\n",
    "        config_list = [{\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "        }]\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        llm_config={\n",
    "            \"config_list\": config_list,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    )\n",
    "    user_proxy = UserProxyAgent(\n",
    "        name=\"user\",\n",
    "        human_input_mode=\"NEVER\",   # non-interactive for notebooks\n",
    "        code_execution_config={\"use_docker\": False}\n",
    "    )\n",
    "\n",
    "    if config_list:\n",
    "        user_proxy.initiate_chat(\n",
    "            assistant,\n",
    "            message=\"Give a concise comparison of GPT-4, Claude, and Mistral (pros/cons & best-fit scenarios).\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Skipped AutoGen chat because OPENAI_API_KEY was not provided.\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"AutoGen section skipped. Missing package:\", e.name)\n",
    "    print(\"Install with: pip install pyautogen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5014822",
   "metadata": {},
   "source": [
    "## 4) (Optional) LangGraph Sketch — Pseudo‑code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code only (no execution):\n",
    "# from langgraph.graph import StateGraph\n",
    "# graph = StateGraph()\n",
    "# graph.add_node(\"start\", StartNode())\n",
    "# graph.add_node(\"search\", SearchNode())\n",
    "# graph.add_node(\"reflect\", ReflectNode())\n",
    "# graph.set_entry_point(\"start\")\n",
    "# graph.add_edge(\"start\", \"search\")\n",
    "# graph.add_edge(\"search\", \"reflect\")\n",
    "# graph.add_edge(\"reflect\", \"search\")  # retry loop"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
